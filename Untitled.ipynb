{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "plt.rcParams[\"axes.labelsize\"] = 18\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# print shape \n",
    "print('train data shape :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data by shing the first five rows \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us round    the total_cost column \n",
    "#data.round(0)\n",
    "#df.round()\n",
    "data['total_cost'] = round(data['total_cost']) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we change the total cost into interger\n",
    "data['total_cost'] = data['total_cost'].astype(int)\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show list of columns \n",
    "list(data.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show Some information about the dataset \n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import preprocessing module \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try to visualize the data \n",
    "\n",
    "plt.matshow(data.corr())\n",
    "plt.xticks(np.arange(23), data.columns, rotation=90)\n",
    "plt.yticks(np.arange(23), data.columns, rotation=0)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We change missing value in the column   to \"No comments\"\n",
    "data['most_impressing'].fillna('No comments', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print('missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we keepo the value from above the cell of the missing value to the missing value \n",
    "data['total_female'].fillna(method='pad', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print('missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we keep the value from below the cell of the missing value to the missing value \n",
    "data['total_male'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print('missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We remove rows with missing values on the column 'Travel with'\n",
    "# drop all rows with NaN values\n",
    "#data.dropna(axis=0,inplace=True)\n",
    "data['travel_with'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print('missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Well i didnt have any better idea to handle those missing values \n",
    "# So i just dropped every row with the missing value in the that column ü§≠ \n",
    "#its a Naught move but worth it üòÇ .. we got no time ‚è≥\n",
    "\n",
    "#Now we have no missing values \n",
    "#Lets go to encoding the all the columns's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove id feature \n",
    "\n",
    "data = data.drop('ID', axis=1)\n",
    "\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import preprocessing module \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numerical Data\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['purpose'] = le.fit_transform(data['purpose'])\n",
    "data['total_cost'] = le.fit_transform(data['total_cost'])\n",
    "data['country'] = le.fit_transform(data['country'])\n",
    "data['age_group'] = le.fit_transform(data['age_group'])\n",
    "data['travel_with'] = le.fit_transform(data['travel_with'])\n",
    "data['total_female'] = le.fit_transform(data['total_female'])\n",
    "data['total_male'] = le.fit_transform(data['total_male'])\n",
    "data['info_source'] = le.fit_transform(data['info_source'])\n",
    "data['main_activity'] = le.fit_transform(data['main_activity'])\n",
    "data['tour_arrangement'] = le.fit_transform(data['tour_arrangement'])\n",
    "data['package_transport_int'] = le.fit_transform(data['package_transport_int'])\n",
    "data['package_accomodation'] = le.fit_transform(data['package_accomodation'])\n",
    "data['package_food'] = le.fit_transform(data['package_food'])\n",
    "data['package_transport_tz'] = le.fit_transform(data['package_transport_tz'])\n",
    "data['package_sightseeing'] = le.fit_transform(data['package_sightseeing'])\n",
    "data['package_guided_tour'] = le.fit_transform(data['package_guided_tour'])\n",
    "data['package_insurance'] = le.fit_transform(data['package_insurance'])\n",
    "data['night_mainland'] = le.fit_transform(data['night_mainland'])\n",
    "data['night_zanzibar'] = le.fit_transform(data['night_zanzibar'])\n",
    "data['payment_mode'] = le.fit_transform(data['payment_mode'])\n",
    "data['first_trip_tz'] = le.fit_transform(data['first_trip_tz'])\n",
    "data['most_impressing'] = le.fit_transform(data['most_impressing'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#show the first five rows \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert categorical features to numerical features\n",
    "\n",
    "\n",
    "categorical_features = ['purpose','info_source','tour_arrangement','age_group',\n",
    "                        'travel_with','main_activity','most_impressing']\n",
    "\n",
    "# One Hot Encoding conversion\n",
    "data = pd.get_dummies(data, prefix_sep='_', columns = categorical_features)\n",
    "\n",
    "\n",
    "#show the shape of the data\n",
    "data.shape\n",
    "\n",
    "\n",
    "#show the first five rows \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into features and target\n",
    "target = data['total_cost']\n",
    "features = data.drop('total_cost', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply SelectKBest class to extract top 27.. best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=21)\n",
    "\n",
    "#train to find best features\n",
    "fit = bestfeatures.fit(features,target)\n",
    "\n",
    "#save in the dataframe \n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(features.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Specs','Score'] \n",
    "\n",
    "#print 27.. best features \n",
    "print(featureScores.nlargest(21,'Score'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#main activity is mostly related with the total cost and also other columns\n",
    "#good thing we didnt mess with it much üòÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and tranform into the 20 best features \n",
    "transformer = SelectKBest(chi2, k=21)\n",
    "\n",
    "#transform from 41 features into top 27.. features\n",
    "top_20_features = transformer.fit_transform(features, target)\n",
    "\n",
    "#show the shape \n",
    "top_20_features.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package importing algorithms \n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model for training \n",
    "#model = RandomForestClassifier()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(features,target)\n",
    "\n",
    "#use inbuilt class feature_importances of tree based classifiers\n",
    "print(model.feature_importances_) \n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feature_importances = pd.Series(model.feature_importances_, index=features.columns)\n",
    "\n",
    "# show the first 30 important features \n",
    "\n",
    "fig= plt.figure(figsize=(25,25))\n",
    "sns.set(font_scale = 3)\n",
    "feature_importances.nlargest(30).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix with Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlations of each features in dataset\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "#plot heat map\n",
    "sns.set(font_scale = 3)\n",
    "# to show number set annot=True\n",
    "d = sns.heatmap(data.corr(),annot=False, cmap=\"RdYlGn\")\n",
    "\n",
    "#save the figure \n",
    "figure = d.get_figure()\n",
    "figure.savefig(\"heatmap_output.png\")\n",
    "\n",
    "# show the heatamp graph \n",
    "d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW CORRELATION OF DATA TO THE TARGET COLUMN \n",
    "features_corr = pd.DataFrame(abs(data.corr()['total_cost']).sort_values(ascending = False)) \n",
    "\n",
    "features_corr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get to the MODELS NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.asarray(data[[\n",
    "'country',\n",
    "'age_group',\n",
    "'travel_with',\n",
    "'total_female',\n",
    "'total_male',\n",
    "'purpose',\n",
    "'main_activity',\n",
    "'info_source',\n",
    "'tour_arrangement',\n",
    "'package_transport_int',\n",
    "'package_accomodation',\n",
    "'package_food',\n",
    "'package_transport_tz',\n",
    "'package_sightseeing',\n",
    "'package_guided_tour',\n",
    "'package_insurance',\n",
    "'night_mainland',\n",
    "'night_zanzibar',\n",
    "'payment_mode',\n",
    "'first_trip_tz',\n",
    "'most_impressing'\n",
    "    ]])\n",
    "Y = np.asarray(data['total_cost'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lineReg = LinearRegression()\n",
    "lineReg.fit(X_train, y_train)\n",
    "print('Score: ', lineReg.score(X_test, y_test))\n",
    "print('Weights: ', lineReg.coef_)\n",
    "\n",
    "plt.plot(lineReg.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge (alpha = 0)\n",
    "reg.fit(X_train, y_train)\n",
    "print('Score: ', reg.score(X_test, y_test))\n",
    "print('Weights: ', reg.coef_)\n",
    "\n",
    "plt.plot(reg.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "coefs = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n",
    "    lineReg = LinearRegression()\n",
    "    lineReg.fit(X_train, y_train)\n",
    "    scores.append(lineReg.score(X_test, y_test))\n",
    "    coefs.append(lineReg.coef_)\n",
    "print('Linear Regression')\n",
    "print(np.mean(scores))\n",
    "print(np.mean(coefs, axis=0))\n",
    "\n",
    "scores = []\n",
    "coefs = []\n",
    "for i in range(500):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n",
    "    lineReg = linear_model.Ridge (alpha = .0)\n",
    "    lineReg.fit(X_train, y_train)\n",
    "    scores.append(lineReg.score(X_test, y_test))\n",
    "    coefs.append(lineReg.coef_)\n",
    "print('\\nRidge Regression')\n",
    "print(np.mean(scores))\n",
    "print(np.mean(coefs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test a random array of a vector\n",
    "reg.predict([[11,  3,  5,  12,2,  4,  1,  12,2,  4,  1,3,8,23,12,2,23,12,43,43,43]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "testdata = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# print shape \n",
    "print('train data shape :', data.shape)\n",
    "\n",
    "testdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove id feature \n",
    "\n",
    "testdata = testdata.drop('ID', axis=1)\n",
    "\n",
    "testdata.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### # Check for missing values\n",
    "print('missing values:', testdata.isnull().sum())\n",
    "\n",
    "testdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove rows with missing values on the column 'Travel with'\n",
    "# drop all rows with NaN values\n",
    "#data.dropna(axis=0,inplace=True)\n",
    "testdata['travel_with'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "#We change missing value in the column   to \"No comments\"\n",
    "testdata['most_impressing'].fillna('No comments', inplace=True)\n",
    "\n",
    "#we keep the value from below the cell of the missing value to the missing value \n",
    "testdata['total_male'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#we keepo the value from above the cell of the missing value to the missing value \n",
    "testdata['total_female'].fillna(method='pad', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print('missing values:', testdata.isnull().sum())\n",
    "\n",
    "\n",
    "testdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numerical Data\n",
    "le = LabelEncoder()\n",
    "\n",
    "testdata['purpose'] = le.fit_transform(testdata['purpose'])\n",
    "testdata['country'] = le.fit_transform(testdata['country'])\n",
    "testdata['age_group'] = le.fit_transform(testdata['age_group'])\n",
    "testdata['travel_with'] = le.fit_transform(testdata['travel_with'])\n",
    "testdata['total_female'] = le.fit_transform(testdata['total_female'])\n",
    "testdata['total_male'] = le.fit_transform(testdata['total_male'])\n",
    "testdata['info_source'] = le.fit_transform(testdata['info_source'])\n",
    "testdata['main_activity'] = le.fit_transform(testdata['main_activity'])\n",
    "testdata['tour_arrangement'] = le.fit_transform(testdata['tour_arrangement'])\n",
    "testdata['package_transport_int'] = le.fit_transform(testdata['package_transport_int'])\n",
    "testdata['package_accomodation'] = le.fit_transform(testdata['package_accomodation'])\n",
    "testdata['package_food'] = le.fit_transform(testdata['package_food'])\n",
    "testdata['package_transport_tz'] = le.fit_transform(testdata['package_transport_tz'])\n",
    "testdata['package_sightseeing'] = le.fit_transform(testdata['package_sightseeing'])\n",
    "testdata['package_guided_tour'] = le.fit_transform(testdata['package_guided_tour'])\n",
    "testdata['package_insurance'] = le.fit_transform(testdata['package_insurance'])\n",
    "testdata['night_mainland'] = le.fit_transform(testdata['night_mainland'])\n",
    "testdata['night_zanzibar'] = le.fit_transform(testdata['night_zanzibar'])\n",
    "testdata['payment_mode'] = le.fit_transform(testdata['payment_mode'])\n",
    "testdata['first_trip_tz'] = le.fit_transform(testdata['first_trip_tz'])\n",
    "testdata['most_impressing'] = le.fit_transform(testdata['most_impressing'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#show the first five rows \n",
    "testdata.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = testdata.values\n",
    "\n",
    "print(my_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict([[1 , 1 , 3 , 3 , 4 , 4 , 7 , 3 , 0 , 1 , 2 , 0 , 0, 0 , 0,  0, 2 , 0 , 0 , 0 , 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test a random array of a vector\n",
    "reg.predict([my_array[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "if i < 5 :     \n",
    "    count = i + 1\n",
    "    print([my_array[i]])\n",
    "    \n",
    "    if i == 3:\n",
    "        break\n",
    "        i += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
